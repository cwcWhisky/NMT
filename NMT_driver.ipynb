{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NMT_driver.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyO1HXL/pT6F98BSxtFQS/vA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markaaronslater/recurrent-NMT/blob/master/NMT_driver.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qngiJLEPEzWv"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZXApLY8E9xw"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVINnIj9E_N0"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3zojHvkFqgL"
      },
      "source": [
        "!pip install subword-nmt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w_rcYx8JVY5"
      },
      "source": [
        "# overwrite these with your own path, and make sure folders already exist.\n",
        "corpus_path = '/content/gdrive/My Drive/iwslt16_en_de/'\n",
        "config_path = '/content/gdrive/My Drive/configs/'\n",
        "data_path = '/content/gdrive/My Drive/data/'\n",
        "model_name = 'my_model' # name of model tensor batches, hyperparameters, etc., saved as pickle file inside data_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0UF-KkzJJV0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaBipTReKPYM"
      },
      "source": [
        "below, steps 1 thru 4 only ever need to be run once (they save their outputs to text and pickle files).\n",
        "\n",
        "\n",
        "step 1 - **apply stanza processors to tokenize and pos-tag the corpuses**\n",
        "\n",
        "\n",
        "> &lt;corpus_name&gt; saved to &lt;corpus_path&gt;/stanza_&lt;corpus_name&gt;, e.g., train.en saved to /content/gdrive/My Drive/iwslt16_en_de/stanza_train.en.pkl.\n",
        "\n",
        "> can retrieve via retrieve_stanza_outputs().\n",
        "\n",
        "\n",
        "step 2 - **decase corpuses using linguistic heuristics that leverage morphological data produced by pos-tagger**\n",
        "\n",
        "> &lt;corpus_name&gt; saved to &lt;corpus_path&gt;/word_&lt;corpus_name&gt;. \n",
        "\n",
        "> can retrieve via read_tokenized_corpuses(prefix='word_')\n",
        "\n",
        "\n",
        "step 3 - **segment corpuses of words into corpuses of subwords**\n",
        "\n",
        "> &lt;corpus_name&gt; saved to &lt;corpus_path&gt;/subword_joint_&lt;corpus_name&gt; or &lt;corpus_path&gt;/subword_ind_&lt;corpus_name&gt;, depending on if learn a joint vocabulary or separate, independent vocabularies, respectively, for the source and target languages.\n",
        "\n",
        "> can retrieve via read_tokenized_corpuses(prefix='subword_joint_') and read_tokenized_corpuses(prefix='subword_ind_')\n",
        "\n",
        "\n",
        "\n",
        "step 4 - dictionary containing all model data is saved to &lt;data_path&gt;/&lt;model_name&gt;, where &lt;model_name&gt; is identifier for which model to load. can retrieve via retrieve_model_data()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW65cehmKRh2"
      },
      "source": [
        "# only meaningful for unit tests on subsets of corpus data, where _start is starting line number,\n",
        "# (using 1-based indexing) and num is how many lines to extract. if num is None, then extract all lines from _start till end of corpus.\n",
        "_start = 1\n",
        "num = 10\n",
        "#num = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJNv2c22F3U-"
      },
      "source": [
        "# step 1 - only ever need to run this cell once. afterward, can load its outputs via retrieve_stanza_outputs()\n",
        "\n",
        "#apply_stanza_processors(\"train.de\", \"train.en\", \"dev.de\", \"dev.en\", \"test.de\", path=corpus_path, )\n",
        "                            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFNueYblGugP"
      },
      "source": [
        "# step 2 - decase corpuses\n",
        "decase_corpuses(\"train.de\", \"train.en\", \"dev.de\", \"dev.en\", \"test.de\", path=corpus_path, _start=_start, num=num):"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZH_5k34It3l"
      },
      "source": [
        "# step 3 - segment words of corpuses into subwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44V9gcJFIxIo"
      },
      "source": [
        "# step 4 - build batches of tensors that can be directly pass to model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJy_MNEYI8rA"
      },
      "source": [
        "# step 5 - instantiate model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4APMWckkI_2u"
      },
      "source": [
        "# step 6 - train model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxK_nCavJBgI"
      },
      "source": [
        "# step 7 - evaluate model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}